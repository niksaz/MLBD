{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><a href=\"https://xgboost.readthedocs.io/en/latest/index.html\" target=\"_blank\">XGBoost</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Baseline-Model\" data-toc-modified-id=\"Baseline-Model-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Baseline Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-Data\" data-toc-modified-id=\"Prepare-Data-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Prepare Data</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Average-Treatment-Effect\" data-toc-modified-id=\"Average-Treatment-Effect-1.1.3.1\"><span class=\"toc-item-num\">1.1.3.1&nbsp;&nbsp;</span>Average Treatment Effect</a></span></li></ul></li></ul></li><li><span><a href=\"#New-Model\" data-toc-modified-id=\"New-Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>New Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-Data\" data-toc-modified-id=\"Prepare-Data-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Prepare Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Categorical-Features\" data-toc-modified-id=\"Categorical-Features-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Categorical Features</a></span></li><li><span><a href=\"#Pipeline\" data-toc-modified-id=\"Pipeline-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>Pipeline</a></span></li></ul></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Evaluation</a></span></li></ul></li></ul></li><li><span><a href=\"#Features-Importance\" data-toc-modified-id=\"Features-Importance-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Features Importance</a></span><ul class=\"toc-item\"><li><span><a href=\"#SHAP\" data-toc-modified-id=\"SHAP-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><a href=\"https://github.com/slundberg/shap\" target=\"_blank\">SHAP</a></a></span></li><li><span><a href=\"#XGBoost-features-importance\" data-toc-modified-id=\"XGBoost-features-importance-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span><a href=\"https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster.get_score\" target=\"_blank\">XGBoost features importance</a></a></span></li></ul></li><li><span><a href=\"#Practical-Lessons-From-Facebook\" data-toc-modified-id=\"Practical-Lessons-From-Facebook-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><a href=\"https://quinonero.net/Publications/predicting-clicks-facebook.pdf\" target=\"_blank\">Practical Lessons From Facebook</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-Data\" data-toc-modified-id=\"Prepare-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Prepare Data</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Make-a-Submission\" data-toc-modified-id=\"Make-a-Submission-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>Make a Submission</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжаем работать над задачей CTR-prediction с использованием датасета от Criteo.\n",
    "\n",
    "Описание задачи и данных можно посмотреть в notebook'e предыдущей практики (`sgd_logreg_nn/notebooks/ctr_prediction_mllib.ipynb`).\n",
    "\n",
    "# [XGBoost](https://xgboost.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "\n",
    "Утановим xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/lib/python3.5/site-packages (1.0.2)\r\n",
      "Requirement already satisfied: scipy in /usr/lib64/python3.5/site-packages (from xgboost) (1.3.3)\r\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.5/site-packages (from xgboost) (1.17.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3.5 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from typing import Dict\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "sys.path.append('./utils')\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"\"\"\n",
    "--jars xgboost4j-spark-0.72.jar,xgboost4j-0.72.jar\n",
    "--py-files sparkxgb.zip pyspark-shell\n",
    "\"\"\".replace('\\n', ' ')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "from metrics import rocauc, logloss, ne, calibration\n",
    "from processing import split_by_col\n",
    "\n",
    "from sparkxgb.xgboost import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на слудующие строки:\n",
    "\n",
    "* ```python\n",
    "sys.path.append('./utils')\n",
    "...\n",
    "from metrics import rocauc, logloss, ne\n",
    "from processing import split_by_col\n",
    "```\n",
    "\n",
    "В папке `utils` находится два файла (`metrics.py`, `processing.py`), которые содержат функции, которые нужно было реализовать в рамках предыдущей практики.\n",
    "\n",
    "\n",
    "* ```python\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"\"\"\n",
    "--jars xgboost4j-spark-0.72.jar,xgboost4j-0.72.jar\n",
    "--py-files sparkxgb.zip pyspark-shell\n",
    "\"\"\"\n",
    "...\n",
    "from sparkxgb.xgboost import *\n",
    "```\n",
    "\n",
    "Для того чтобы в рамках инфраструктуры Spark можно было использовать XGBoost, мы воспользуемся библиотекой [XGBoost4J](https://xgboost.readthedocs.io/en/latest/jvm/xgboost4j_spark_tutorial.html).\n",
    "\n",
    "В ходе выполнения занятий может быть полезно ознакомиться с исходным кодом обертки для питона, который находится в архиве `sparkxgb.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/criteo/dac'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')\n",
    "\n",
    "MODEL_DIR = '/workspace/models/criteo/dac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLING_RATE = 0.1\n",
    "SEED=82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = ['_c{}'.format(i) for i in range(1, 14)]\n",
    "cat_columns = ['_c{}'.format(i) for i in range(14, 40)][:2]\n",
    "len(num_columns), len(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся пайплайном из предыдущей практики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel.load(os.path.join(DATA_PATH, 'pipeline_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_ffdd8d524b01,\n",
       " StringIndexer_547ed9cdbe45,\n",
       " OneHotEncoderEstimator_b3d576ca1390,\n",
       " VectorAssembler_9c298301fb70]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1389, 552)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pipeline_model.stages[0].labels), len(pipeline_model.stages[1].labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговая размерность пространства фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = len(num_columns) + len(pipeline_model.stages[0].labels) + len(pipeline_model.stages[1].labels)\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3667985"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaObject.__init__.<locals>.<lambda> at 0x7fd23aab8e18>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1293, in <lambda>\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 625, in _garbage_collect_object\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 920, in garbage_collect_object\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 983, in send_command\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 931, in _get_connection\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 937, in _create_connection\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1071, in start\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1087, in _authenticate_connection\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1152, in send_command\n",
      "  File \"/usr/lib64/python3.5/socket.py\", line 576, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(False, TRAIN_SAMPLING_RATE, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBoostEstimator(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\",\n",
    "    colsample_bytree=0.9,\n",
    "    eta=0.15,\n",
    "    gamma=0.9,\n",
    "    max_depth=8,\n",
    "    min_child_weight=50.0,\n",
    "    subsample=0.9,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss', \n",
    "    silent=0,\n",
    "    num_round=20,\n",
    "    nthread=1,\n",
    "    nworkers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimator.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем [booster](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster) обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_BASELINE_PATH = os.path.join(MODEL_DIR, 'xgb.model')\n",
    "\n",
    "model._call_java(\"booster\").saveModel(XGB_BASELINE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Treatment Effect\n",
    "\n",
    "Пусть даны две экспериментальные группы treatment ($T$) и control ($C$), где\n",
    "\n",
    "* `treatment` - группа с изменением (например, новая модель)\n",
    "* `control` - группа без изменений\n",
    "\n",
    "Рассмотрим метрику $X$, значение которой мы расчитали для наших групп ($X_T, X_C$).\n",
    "\n",
    "Тогда под ATE будем иметь в виду\n",
    "$$ \\Delta\\% = \\frac{X_T - X_C}{X_C} \\cdot 100 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ate(groups, control_name) -> pd.DataFrame:\n",
    "    \"\"\"Get Average Treatment Effect\n",
    "    groups - dictionary where keys - names of models, values - dicts of pairs <metric_name>, <metric_value>\n",
    "    control_name - name of baseline model\n",
    "    \n",
    "    return pd.DataFrame (rows corresponds to metrics, cols corresponds to models and ATE with respect to control)\n",
    "    \"\"\"\n",
    "    \n",
    "    metric_names = []\n",
    "    for metric_name_values in groups.values():\n",
    "        for metric_name, _ in metric_name_values.items():\n",
    "            if metric_name not in metric_names:\n",
    "                metric_names.append(metric_name)\n",
    "    metric_names = list(sorted(metric_names))\n",
    "    \n",
    "    if control_name not in groups:\n",
    "        raise ValueError(\"Control experiment is not in the group.\")\n",
    "    control_values = groups[control_name]\n",
    "    if len(control_values) != len(metric_names):\n",
    "        raise ValueError(\"Control experiment does not have all the metrics computed.\")\n",
    "\n",
    "    model_names = list(sorted(groups.keys()))\n",
    "    metric_model_ates = []\n",
    "    for metric_name in metric_names:\n",
    "        control_value = control_values[metric_name]\n",
    "        model_ates = []\n",
    "        for model_name in model_names:\n",
    "            if metric_name in groups[model_name]:\n",
    "                ate = (groups[model_name][metric_name] - control_value) / control_value * 100\n",
    "            else:\n",
    "                ate = None\n",
    "            model_ates.append(ate)\n",
    "        metric_model_ates.append(model_ates)\n",
    "\n",
    "    ates_df = pd.DataFrame(data=metric_model_ates, index=metric_names, columns=model_names)\n",
    "    return ates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_AUC_HANDLE = 'Area Under ROC'\n",
    "CALIBRATION_HANDLE = 'Calibration'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metrics = {}\n",
    "baseline_metrics[ROC_AUC_HANDLE] = rocauc(model, test_df, probabilities_col='probabilities')\n",
    "baseline_metrics[CALIBRATION_HANDLE] = calibration(model, test_df, probabilities_col='probabilities')\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_BASELINE_HANDLE = '1.xgb_baseline'\n",
    "all_metrics[XGB_BASELINE_HANDLE] = baseline_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты с логрег моделью из предыдущей практики.\n",
    "\n",
    "1. Загрузить обученную `LogReg` модель\n",
    "2. Посчитать метрики на `test_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "\n",
    "LOG_REG_MODEL_PATH = os.path.join(MODEL_DIR, 'log_reg_model')\n",
    "\n",
    "log_reg_model = LogisticRegressionModel.load(LOG_REG_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_reg_metrics = {}\n",
    "log_reg_metrics[ROC_AUC_HANDLE] = rocauc(log_reg_model, test_df)\n",
    "log_reg_metrics[CALIBRATION_HANDLE] = calibration(log_reg_model, test_df)\n",
    "log_reg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_REG_HANDLE = '2.logistic_regression'\n",
    "all_metrics[LOG_REG_HANDLE] = log_reg_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построить таблицу ATE используя метод `get_ate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ate(all_metrics, XGB_BASELINE_HANDLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Model\n",
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH)\n",
    "df = df.sample(False, SAMPLE_RATE, seed=SEED)\n",
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Features\n",
    "\n",
    "See [Doc](https://spark.apache.org/docs/latest/ml-pipeline.html) for additional details on Transformers and Encoders.\n",
    "\n",
    "Implement classes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params\n",
    "from pyspark import keyword_only\n",
    "\n",
    "\n",
    "class MeanTargetEncoderModel(\n",
    "    pyspark.ml.Model,\n",
    "    HasInputCol,\n",
    "    HasOutputCol,\n",
    "    pyspark.ml.util.DefaultParamsWritable,\n",
    "    pyspark.ml.util.DefaultParamsReadable):\n",
    "    \"\"\"Fitted Model\"\"\"\n",
    "    \n",
    "    def __init__(self):        \n",
    "        super(MeanTargetEncoderModel, self).__init__()\n",
    "        self.inputOutputMapping = Param(self, \"inputOutputMapping\", \"inputOutputMapping\")\n",
    "        self._setDefault(inputOutputMapping={})\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol, outputCol, inputOutputMapping):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setInputOutputMapping(self, value):\n",
    "        return self._set(inputOutputMapping=value)\n",
    "\n",
    "    def getInputOutputMapping(self):\n",
    "        return self.getOrDefault(self.inputOutputMapping)\n",
    "        \n",
    "    def transform(self, dataset: pyspark.sql.DataFrame) -> pyspark.sql.DataFrame:\n",
    "        inputOutputMapping = self.getInputOutputMapping()\n",
    "        def map_column_using_mapping(input_value, default_value=0.0):\n",
    "            return inputOutputMapping.get(input_value, default_value)\n",
    "    \n",
    "        map_column_using_mapping_udf = F.udf(map_column_using_mapping, FloatType())\n",
    "\n",
    "        return dataset \\\n",
    "            .withColumn(self.getOutputCol(), map_column_using_mapping_udf(self.getInputCol()))\n",
    "\n",
    "\n",
    "class MeanTargetEncoder(pyspark.ml.Estimator):\n",
    "    \"\"\"Estimator\"\"\"\n",
    "\n",
    "    def __init__(self, inputCol: str, featuresCol: str, outputCol: str,):\n",
    "        self.inputCol = inputCol\n",
    "        self.featuresCol = featuresCol\n",
    "        self.outputCol = outputCol\n",
    "    \n",
    "    def fit(self, dataset: pyspark.sql.DataFrame) -> MeanTargetEncoderModel:\n",
    "        inputOutputMapping = dataset \\\n",
    "            .groupby(self.inputCol) \\\n",
    "            .agg(F.mean(self.featuresCol).alias(self.outputCol)) \\\n",
    "            .select(F.col(self.inputCol), F.col(self.outputCol)) \\\n",
    "            .rdd \\\n",
    "            .collectAsMap()\n",
    "        mte_model = MeanTargetEncoderModel()\n",
    "        mte_model.setParams(\n",
    "            inputCol=self.inputCol, outputCol=self.outputCol, inputOutputMapping=inputOutputMapping)\n",
    "        return mte_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_enc_columns = [cat_col + '_enc' for cat_col in cat_columns]\n",
    "\n",
    "cat_col, cat_enc_col = cat_columns[0], cat_enc_columns[0]\n",
    "mean_target_encoder = MeanTargetEncoder(cat_col, '_c0', cat_enc_col)\n",
    "mean_target_encoder_model = mean_target_encoder.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target_encoder_model.transform(df).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "cat_enc_columns = [cat_col + '_enc' for cat_col in cat_columns]\n",
    "\n",
    "mean_target_encoders = [MeanTargetEncoder(cat_col, '_c0', cat_enc_col) \n",
    "                        for cat_col, cat_enc_col in zip(cat_columns, cat_enc_columns)]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=num_columns + cat_enc_columns, outputCol=\"features\").setHandleInvalid(\"keep\")\n",
    "\n",
    "pipeline = Pipeline(stages=mean_target_encoders + [assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTE_PIPELINE_MODEL_PATH = os.path.join(DATA_PATH, 'pipeline_model_2')\n",
    "\n",
    "pipeline_model = pipeline.fit(df)\n",
    "pipeline_model.write().overwrite().save(MTE_PIPELINE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel.load(MTE_PIPELINE_MODEL_PATH)\n",
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = len(train_df.take(1)[0].features)\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Train XGBoost on the new set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBoostEstimator(\n",
    "    featuresCol=\"features\", \n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\",\n",
    "    colsample_bytree=0.9,\n",
    "    eta=0.15,\n",
    "    gamma=0.9,\n",
    "    max_depth=8,\n",
    "    min_child_weight=50.0,\n",
    "    subsample=0.9,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss', \n",
    "    silent=0,\n",
    "    num_round=20,\n",
    "    nthread=1,\n",
    "    nworkers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estimator.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_MTE_PATH = os.path.join(MODEL_DIR, 'xgb.model_2')\n",
    "\n",
    "model._call_java(\"booster\").saveModel(XGB_MTE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнить результаты новой модели с `xgb_baseline` и `log_reg` с помощью функции `get_ate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mte_metrics = {}\n",
    "xgb_mte_metrics[ROC_AUC_HANDLE] = rocauc(model, test_df, probabilities_col='probabilities')\n",
    "xgb_mte_metrics[CALIBRATION_HANDLE] = calibration(model, test_df, probabilities_col='probabilities')\n",
    "xgb_mte_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_MTE_HANDLE = '3.xgb_mte'\n",
    "\n",
    "all_metrics[XGB_MTE_HANDLE] = xgb_mte_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ate(all_metrics, XGB_BASELINE_HANDLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Importance\n",
    "\n",
    "## [SHAP](https://github.com/slundberg/shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3.5 install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import xgboost as xgb\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "bst = xgb.Booster()\n",
    "bst.load_model(XGB_MTE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имея `booster` модели можно, например, посмотреть на то какие деревья получились в итоге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bst.get_dump(dump_format=\"text\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(False, 0.05, seed=SEED)\n",
    "sample_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector, SparseVector, _convert_to_vector\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "\n",
    "def df_to_csr(df, dim):\n",
    "    data = []\n",
    "    row_ind = []\n",
    "    col_ind = []\n",
    "    \n",
    "    vecs = df.rdd.map(lambda row: row.features).collect()\n",
    "    for i, vec in enumerate(vecs):\n",
    "        if isinstance(vec, SparseVector):\n",
    "            indices = vec.indices\n",
    "        elif isinstance(vec, DenseVector):\n",
    "            indices = range(len(vec))\n",
    "        else:\n",
    "            raise NotImplementedValue()\n",
    "        \n",
    "        for idx, val in zip(indices, vec.values):\n",
    "            data.append(val)\n",
    "            row_ind.append(i)\n",
    "            col_ind.append(idx)\n",
    "        \n",
    "    return csr_matrix((data, (row_ind, col_ind)), shape=(len(vecs), dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = df_to_csr(sample_df, dim)\n",
    "dtest = xgb.DMatrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "explainer = shap.TreeExplainer(bst)\n",
    "shap_values = explainer.shap_values(dtest, tree_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_arr, max_display=20, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [XGBoost features importance](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.Booster.get_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_score(booster, importance):\n",
    "    gains_xgb = booster.get_score(importance_type=importance)\n",
    "    gains = {}\n",
    "    for f, g in gains_xgb.items():\n",
    "        gains[f] = g\n",
    "    sorted_gains = sorted(list(gains.items()), key=lambda x: -x[1])\n",
    "    return sorted_gains\n",
    "\n",
    "\n",
    "features_scores = get_feature_score(bst, 'gain')[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "f_names, f_scores = zip(*features_scores)\n",
    "features_scores_pdf = pd.DataFrame({'feature': f_names, 'gain': f_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(figsize=(8,8))\n",
    "ax = sns.barplot(x='gain', y='feature', data=features_scores_pdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Practical Lessons From Facebook](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)\n",
    "\n",
    "## Prepare Data\n",
    "\n",
    "* Реализуйте модель из статьи (LogReg поверх XGBoost)\n",
    "\n",
    "* Попробуйте реализовать Negatives Subsampling + Re-calibration описанный в статье (доп. баллы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH) \\\n",
    "    .fillna(0, subset=num_columns)\n",
    "df = df.sample(False, SAMPLE_RATE, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = PipelineModel.load(MTE_PIPELINE_MODEL_PATH)\n",
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tree_leaves_to_row(row, has_label=True):\n",
    "    result = [row.id]\n",
    "    if has_label:\n",
    "        result.append(row.label)\n",
    "\n",
    "    samples = np.array([row.features.toArray()])\n",
    "    xgb_matrix = xgb.DMatrix(samples)\n",
    "    bst = xgb.Booster()\n",
    "    bst.load_model(XGB_MTE_PATH)\n",
    "    leaves = bst.predict(xgb_matrix, pred_leaf=True)[0]\n",
    "    for leaf in leaves:\n",
    "        result.append(int(leaf))\n",
    "    return result\n",
    "\n",
    "bst = xgb.Booster()\n",
    "bst.load_model(XGB_MTE_PATH)\n",
    "num_trees = len(bst.get_dump())\n",
    "leaf_columns = [\"leaf\" + str(leaf_num) for leaf_num in range(num_trees)]\n",
    "\n",
    "df = df \\\n",
    "    .rdd \\\n",
    "    .map(lambda row: add_tree_leaves_to_row(row, has_label=True)) \\\n",
    "    .toDF([\"id\", \"label\"] + leaf_columns) \\\n",
    "    .cache()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "leaf_encoded_columns = [leaf_col + '_enc' for leaf_col in leaf_columns]\n",
    "\n",
    "leaf_encoder = OneHotEncoderEstimator(inputCols=leaf_columns, outputCols=leaf_encoded_columns)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=leaf_encoded_columns, outputCol=\"features\").setHandleInvalid(\"keep\")\n",
    "\n",
    "pipeline = Pipeline(stages=[leaf_encoder, assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREE_PIPELINE_MODEL_PATH = os.path.join(DATA_PATH, 'pipeline_model_3')\n",
    "\n",
    "pipeline_model = pipeline.fit(df)\n",
    "pipeline_model.write().overwrite().save(TREE_PIPELINE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = PipelineModel.load(TREE_PIPELINE_MODEL_PATH)\n",
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .select('label', 'features', 'id') \\\n",
    "    .cache()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "def find_the_best_log_reg_model(train_df, val_df, negative_downsampling_rate):\n",
    "    best_model = None\n",
    "    best_rocauc = None\n",
    "    for regParam in [1e-1]:  #  [0.0, 1e-1, 1e-2, 1e-3]:\n",
    "        for elasticNetParam in [1e-2]:  # [0.0, 1e-1, 1e-2, 1e-3]:\n",
    "            for standardization in [True]:\n",
    "                lr = LogisticRegression(\n",
    "                    regParam=regParam, elasticNetParam=elasticNetParam, standardization=standardization,\n",
    "                    probabilityCol='probabilities')\n",
    "                lr_model = lr.fit(train_df)\n",
    "                lr_rocauc = rocauc(\n",
    "                    lr_model,\n",
    "                    val_df,\n",
    "                    probabilities_col='probabilities',\n",
    "                    negative_downsampling_rate=negative_downsampling_rate)\n",
    "                if best_rocauc is None or best_rocauc < lr_rocauc:\n",
    "                    print(\"regParam={} elasticNetParam={} standardization={}\".format(\n",
    "                        regParam, elasticNetParam, standardization))\n",
    "                    print(\"Improved ROCAUC from {} to {} with the params.\".format(best_rocauc, lr_rocauc))\n",
    "                    best_model = lr_model\n",
    "                    best_rocauc = lr_rocauc\n",
    "    return best_model, best_rocauc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative subsampling and recalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it is not the best way to do downsampling and comparing it with the performance with on the 100% dataset, we will still do it. To do a fair comparison, we should have compared the equal amounts of samples, i.e. 10% of all data downsampled uniformly vs. all postivie + the negative downsampling rate which would bring the total number of samples equal to 10% of all the dataset.\n",
    "\n",
    "The inconvenience is in the dataset preprocessing and the structure of the code above which compares all previous models on a 10% test set of a 50% uniformly downsampled dataset.\n",
    "\n",
    "The final model for the contest will do model selection by first splitting the whole set and then operating only on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_df = train_df.filter(F.col('label') == 1.0)\n",
    "positive_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_train_df = train_df.filter(F.col('label') == 0.0)\n",
    "negative_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_rocauc, best_neg_rate = None, None, None\n",
    "for segment in range(1, 21):\n",
    "    negative_downsampling_rate = segment * 0.05\n",
    "    print('*' * 100)\n",
    "    print('NEGATIVE DOWNSAMPLING RATE =', negative_downsampling_rate)\n",
    "    rebalanced_train_df = negative_train_df \\\n",
    "        .sample(False, negative_downsampling_rate, seed=SEED) \\\n",
    "        .union(positive_train_df)\n",
    "    cur_model, cur_rocauc = find_the_best_log_reg_model(\n",
    "        rebalanced_train_df,\n",
    "        val_df,\n",
    "        negative_downsampling_rate)\n",
    "    if best_rocauc is None or best_rocauc < cur_rocauc:\n",
    "        print('Imporved the global best ROCAUC model!')\n",
    "        best_model = cur_model\n",
    "        best_rocauc = cur_rocauc\n",
    "        best_neg_rate = negative_downsampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rocauc, best_neg_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_REG_XGB_MODEL_PATH = os.path.join(MODEL_DIR, 'log_reg_xgb_model_' + str(best_neg_rate))\n",
    "\n",
    "best_model.write().overwrite().save(LOG_REG_XGB_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration(model, df) is implemented in the utils.metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните новую модель со всеми предыдущими с помощью `get_ate`. При сравнении использовать еще и метрику calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_xgb_metrics = {}\n",
    "logistic_regression_xgb_metrics[ROC_AUC_HANDLE] = rocauc(\n",
    "    best_model, test_df, probabilities_col='probabilities', negative_downsampling_rate=best_neg_rate)\n",
    "logistic_regression_xgb_metrics[CALIBRATION_HANDLE] = calibration(\n",
    "    best_model, test_df, probabilities_col='probabilities', negative_downsampling_rate=best_neg_rate)\n",
    "logistic_regression_xgb_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_REG_XGB_MODEL_HANDLE = '4.logistic_regression_xgb'\n",
    "all_metrics[LOG_REG_XGB_MODEL_HANDLE] = logistic_regression_xgb_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ate(all_metrics, XGB_BASELINE_HANDLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Submission\n",
    "\n",
    "Если в результате работы получилась модель, которая лучше чем ЛогРег из предыдущей практики, то точно нужно сделать submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH = '/workspace/data/mlbd-20-ctr-prediction-1'\n",
    "TEST_TEST_PATH = os.path.join(TEST_DATA_PATH, 'test.csv')\n",
    "\n",
    "comp_df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TEST_TEST_PATH) \\\n",
    "    .fillna(0, subset=num_columns)\n",
    "\n",
    "comp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = PipelineModel.load(MTE_PIPELINE_MODEL_PATH)\n",
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = pipeline_model \\\n",
    "    .transform(comp_df) \\\n",
    "    .select('features', 'id') \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = comp_df \\\n",
    "    .rdd \\\n",
    "    .map(lambda row: add_tree_leaves_to_row(row, has_label=False)) \\\n",
    "    .toDF([\"id\"] + leaf_columns) \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = PipelineModel.load(TREE_PIPELINE_MODEL_PATH)\n",
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = pipeline_model \\\n",
    "    .transform(comp_df) \\\n",
    "    .select('features', 'id') \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_prediction = best_model.transform(comp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df_prediction.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_predictions = comp_df_prediction \\\n",
    "    .rdd \\\n",
    "    .map(lambda row: (row.id, row.probabilities[1])) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = os.path.join(TEST_DATA_PATH, 'submission_logistic_regression_xgb.csv')\n",
    "with open(submission_path, 'w') as writer:\n",
    "    writer.write(\"id,proba\\n\")\n",
    "    for row in comp_predictions:\n",
    "        writer.write(\",\".join(map(str, row))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
