{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of the gradinet boosting and hyperopt notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/lib/python3.5/site-packages (1.0.2)\n",
      "Requirement already satisfied: hyperopt in /usr/lib/python3.5/site-packages (0.2.3)\n",
      "Requirement already satisfied: scipy in /usr/lib64/python3.5/site-packages (from xgboost) (1.3.3)\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.5/site-packages (from xgboost) (1.17.2)\n",
      "Requirement already satisfied: networkx==2.2 in /usr/lib/python3.5/site-packages (from hyperopt) (2.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3.5/site-packages (from hyperopt) (1.14.0)\n",
      "Requirement already satisfied: cloudpickle in /usr/lib/python3.5/site-packages (from hyperopt) (1.3.0)\n",
      "Requirement already satisfied: future in /usr/lib/python3.5/site-packages (from hyperopt) (0.18.2)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.5/site-packages (from hyperopt) (4.44.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3.5/site-packages (from networkx==2.2->hyperopt) (4.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3.5 install xgboost hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark import keyword_only\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"\"\"\n",
    "--jars xgboost4j-spark-0.72.jar,xgboost4j-0.72.jar\n",
    "--py-files sparkxgb.zip pyspark-shell\n",
    "\"\"\".replace('\\n', ' ')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "sys.path.append('../gradient_boosting/notebooks')\n",
    "\n",
    "from sparkxgb.xgboost import *\n",
    "\n",
    "from utils.metrics import rocauc, logloss, ne, calibration, df_with_proba_column\n",
    "from utils.processing import split_by_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ate(groups, control_name) -> pd.DataFrame:\n",
    "    \"\"\"Get Average Treatment Effect\n",
    "    groups - dictionary where keys - names of models, values - dicts of pairs <metric_name>, <metric_value>\n",
    "    control_name - name of baseline model\n",
    "    \n",
    "    return pd.DataFrame (rows corresponds to metrics, cols corresponds to models and ATE with respect to control)\n",
    "    \"\"\"\n",
    "    \n",
    "    metric_names = []\n",
    "    for metric_name_values in groups.values():\n",
    "        for metric_name, _ in metric_name_values.items():\n",
    "            if metric_name not in metric_names:\n",
    "                metric_names.append(metric_name)\n",
    "    metric_names = list(sorted(metric_names))\n",
    "    \n",
    "    if control_name not in groups:\n",
    "        raise ValueError(\"Control experiment is not in the group.\")\n",
    "    control_values = groups[control_name]\n",
    "    if len(control_values) != len(metric_names):\n",
    "        raise ValueError(\"Control experiment does not have all the metrics computed.\")\n",
    "\n",
    "    model_names = list(sorted(groups.keys()))\n",
    "    metric_model_ates = []\n",
    "    for metric_name in metric_names:\n",
    "        control_value = control_values[metric_name]\n",
    "        model_ates = []\n",
    "        for model_name in model_names:\n",
    "            if metric_name in groups[model_name]:\n",
    "                ate = (groups[model_name][metric_name] - control_value) / control_value * 100\n",
    "            else:\n",
    "                ate = None\n",
    "            model_ates.append(ate)\n",
    "        metric_model_ates.append(model_ates)\n",
    "\n",
    "    ates_df = pd.DataFrame(data=metric_model_ates, index=metric_names, columns=model_names)\n",
    "    return ates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_AUC_HANDLE = 'Area Under ROC'\n",
    "CALIBRATION_HANDLE = 'Calibration Δ'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/workspace/data/criteo/dac'\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 0.4\n",
    "SEED = 82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TRAIN_PATH) \\\n",
    "    .sample(False, SAMPLE_RATE, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      " |-- _c29: string (nullable = true)\n",
      " |-- _c30: string (nullable = true)\n",
      " |-- _c31: string (nullable = true)\n",
      " |-- _c32: string (nullable = true)\n",
      " |-- _c33: string (nullable = true)\n",
      " |-- _c34: string (nullable = true)\n",
      " |-- _c35: string (nullable = true)\n",
      " |-- _c36: string (nullable = true)\n",
      " |-- _c37: string (nullable = true)\n",
      " |-- _c38: string (nullable = true)\n",
      " |-- _c39: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['_c1',\n",
       "  '_c2',\n",
       "  '_c3',\n",
       "  '_c4',\n",
       "  '_c5',\n",
       "  '_c6',\n",
       "  '_c7',\n",
       "  '_c8',\n",
       "  '_c9',\n",
       "  '_c10',\n",
       "  '_c11',\n",
       "  '_c12',\n",
       "  '_c13'],\n",
       " ['_c14',\n",
       "  '_c15',\n",
       "  '_c16',\n",
       "  '_c17',\n",
       "  '_c18',\n",
       "  '_c19',\n",
       "  '_c20',\n",
       "  '_c21',\n",
       "  '_c22',\n",
       "  '_c23',\n",
       "  '_c24',\n",
       "  '_c25',\n",
       "  '_c26',\n",
       "  '_c27',\n",
       "  '_c28',\n",
       "  '_c29',\n",
       "  '_c30',\n",
       "  '_c31',\n",
       "  '_c32',\n",
       "  '_c33',\n",
       "  '_c34',\n",
       "  '_c35',\n",
       "  '_c36',\n",
       "  '_c37',\n",
       "  '_c38',\n",
       "  '_c39'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_FEATURES_TO_USE = 13\n",
    "CATEGORICAL_FEATURES_TO_USE = 26\n",
    "MEAN_TARGET_ENCODER_MIN_EXAMPLES = 50\n",
    "\n",
    "num_indexes = range(NUM_FEATURES_TO_USE)\n",
    "num_columns = ['_c{}'.format(i) for i in range(1, 14)]\n",
    "num_columns = [num_columns[num_index] for num_index in num_indexes]\n",
    "\n",
    "cat_indexes = range(CATEGORICAL_FEATURES_TO_USE)\n",
    "cat_columns = ['_c{}'.format(i) for i in range(14, 40)]\n",
    "cat_columns = [cat_columns[cat_index] for cat_index in cat_indexes]\n",
    "\n",
    "num_columns, cat_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_by_col(df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTargetEncoderModel(\n",
    "    pyspark.ml.Model,\n",
    "    HasInputCol,\n",
    "    HasOutputCol,\n",
    "    pyspark.ml.util.DefaultParamsWritable,\n",
    "    pyspark.ml.util.DefaultParamsReadable):\n",
    "    \"\"\"Fitted Model\"\"\"\n",
    "    \n",
    "    def __init__(self):        \n",
    "        super(MeanTargetEncoderModel, self).__init__()\n",
    "        self.inputOutputMapping = Param(self, \"inputOutputMapping\", \"inputOutputMapping\")\n",
    "        self._setDefault(inputOutputMapping={})\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, inputCol, outputCol, inputOutputMapping):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def setInputOutputMapping(self, value):\n",
    "        return self._set(inputOutputMapping=value)\n",
    "\n",
    "    def getInputOutputMapping(self):\n",
    "        return self.getOrDefault(self.inputOutputMapping)\n",
    "        \n",
    "    def transform(self, dataset: pyspark.sql.DataFrame) -> pyspark.sql.DataFrame:\n",
    "        inputOutputMapping = self.getInputOutputMapping()\n",
    "        total_sum = sum(map(lambda sum_cnt: sum_cnt[0], inputOutputMapping.values()))\n",
    "        total_cnt = sum(map(lambda sum_cnt: sum_cnt[1], inputOutputMapping.values()))\n",
    "        mean_default_value = float(total_sum / total_cnt)\n",
    "        def map_column_using_mapping(input_value):\n",
    "            sum_cnt = inputOutputMapping.get(input_value, (0, 0))\n",
    "            if sum_cnt[1] < MEAN_TARGET_ENCODER_MIN_EXAMPLES:\n",
    "                return mean_default_value\n",
    "            else:\n",
    "                return float(sum_cnt[0] / sum_cnt[1])\n",
    "    \n",
    "        map_column_using_mapping_udf = F.udf(map_column_using_mapping, FloatType())\n",
    "\n",
    "        return dataset \\\n",
    "            .withColumn(self.getOutputCol(), map_column_using_mapping_udf(self.getInputCol()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanTargetEncoder(pyspark.ml.Estimator):\n",
    "    \"\"\"Estimator.\"\"\"\n",
    "\n",
    "    def __init__(self, inputCol: str, featuresCol: str, outputCol: str):\n",
    "        self.inputCol = inputCol\n",
    "        self.featuresCol = featuresCol\n",
    "        self.outputCol = outputCol\n",
    "    \n",
    "    def fit(self, dataset: pyspark.sql.DataFrame) -> MeanTargetEncoderModel:\n",
    "        inputOutputMapping = dataset \\\n",
    "            .groupby(self.inputCol) \\\n",
    "            .agg(F.sum(self.featuresCol).alias(self.outputCol + \"_sum\"), \n",
    "                 F.count(self.featuresCol).alias(self.outputCol + \"_count\")) \\\n",
    "            .select(\n",
    "                F.col(self.inputCol), F.col(self.outputCol + \"_sum\"), F.col(self.outputCol + \"_count\")) \\\n",
    "            .rdd \\\n",
    "            .map(lambda row: (row[0], (row[1], row[2]))) \\\n",
    "            .collectAsMap()\n",
    "        mte_model = MeanTargetEncoderModel()\n",
    "        mte_model.setParams(\n",
    "            inputCol=self.inputCol, outputCol=self.outputCol, inputOutputMapping=inputOutputMapping)\n",
    "        return mte_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=1, _c1=0, _c2=277, _c3=0, _c4=3, _c5=7318, _c6=24, _c7=6, _c8=3, _c9=98, _c10=0, _c11=1, _c12=0, _c13=3, _c14='8cf07265', _c15='9adf4cf9', _c16='2e76fb61', _c17='0b1ad9da', _c18='4cf72387', _c19='fe6b92e5', _c20='75dcaaca', _c21='0b153874', _c22='a73ee510', _c23='3b08e48b', _c24='8aabdae8', _c25='9886a0a7', _c26='edcf17ce', _c27='07d13a8f', _c28='2aaebd23', _c29='338c0d09', _c30='e5ba7672', _c31='c7dbecd5', _c32=None, _c33=None, _c34='60d2d691', _c35=None, _c36='3a171ecb', _c37='90b6276f', _c38=None, _c39=None, id=30, _c14_enc=0.2543465197086334)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_enc_columns = [cat_col + '_enc' for cat_col in cat_columns]\n",
    "\n",
    "cat_col, cat_enc_col = cat_columns[0], cat_enc_columns[0]\n",
    "mean_target_encoder = MeanTargetEncoder(cat_col, '_c0', cat_enc_col)\n",
    "mean_target_encoder_model = mean_target_encoder.fit(train_df)\n",
    "mean_target_encoder_model.transform(df).take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n",
    "\n",
    "# cat_index_columns = [col_name + \"_index\" for col_name in cat_columns]\n",
    "# cat_vec_columns = [col_name + \"_vec\" for col_name in cat_columns]\n",
    "\n",
    "# cat_indexers = [\n",
    "#     StringIndexer(inputCol=cat_column, outputCol=cat_index_column, handleInvalid='keep')\n",
    "#     for cat_column, cat_index_column in zip(cat_columns, cat_index_columns)]\n",
    "# ohe_estimator = OneHotEncoderEstimator(inputCols=cat_index_columns, outputCols=cat_vec_columns)\n",
    "\n",
    "# assembler = VectorAssembler(inputCols=num_columns + cat_vec_columns, outputCol=\"features\")\n",
    "\n",
    "# pipeline = Pipeline(stages=cat_indexers + [ohe_estimator, assembler])\n",
    "\n",
    "mean_target_encoders = [\n",
    "    MeanTargetEncoder(cat_col, '_c0', cat_enc_col) \n",
    "    for cat_col, cat_enc_col in zip(cat_columns, cat_enc_columns)]\n",
    "\n",
    "assembler = \\\n",
    "    VectorAssembler(inputCols=num_columns + cat_enc_columns, outputCol=\"features\") \\\n",
    "    .setHandleInvalid(\"keep\")\n",
    "\n",
    "pipeline = Pipeline(stages=mean_target_encoders + [assembler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTE_PIPELINE_MODEL_PATH = os.path.join(DATA_PATH, 'ctr_pipeline_model')\n",
    "\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "pipeline_model.write().overwrite().save(MTE_PIPELINE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MeanTargetEncoderModel_43109fb33246,\n",
       " MeanTargetEncoderModel_22d505e4fbaa,\n",
       " MeanTargetEncoderModel_5beb25c2f649,\n",
       " MeanTargetEncoderModel_66cfb8b2eb53,\n",
       " MeanTargetEncoderModel_fe74fac2940a,\n",
       " MeanTargetEncoderModel_3f04f4e963f5,\n",
       " MeanTargetEncoderModel_5dc3f36923fc,\n",
       " MeanTargetEncoderModel_c7f740e2261b,\n",
       " MeanTargetEncoderModel_0c8288cf738e,\n",
       " MeanTargetEncoderModel_5a55a9bdc966,\n",
       " MeanTargetEncoderModel_bc7c443f409f,\n",
       " MeanTargetEncoderModel_f32dbc83ead2,\n",
       " MeanTargetEncoderModel_14acab1e0d8d,\n",
       " MeanTargetEncoderModel_06712ee47896,\n",
       " MeanTargetEncoderModel_906e618e0203,\n",
       " MeanTargetEncoderModel_ae33dd97b624,\n",
       " MeanTargetEncoderModel_6d08991d7a7e,\n",
       " MeanTargetEncoderModel_2558b2fac327,\n",
       " MeanTargetEncoderModel_6b3f6ad5d1fb,\n",
       " MeanTargetEncoderModel_6e2542552212,\n",
       " MeanTargetEncoderModel_65422be95150,\n",
       " MeanTargetEncoderModel_ca42f23b1b53,\n",
       " MeanTargetEncoderModel_92e8361c8722,\n",
       " MeanTargetEncoderModel_2c3b89e95933,\n",
       " MeanTargetEncoderModel_7ac311e2b809,\n",
       " MeanTargetEncoderModel_915fe3374972,\n",
       " VectorAssembler_7554d7d39318]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model = PipelineModel.load(MTE_PIPELINE_MODEL_PATH)\n",
    "pipeline_model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pipeline_model \\\n",
    "    .transform(train_df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "val_df = pipeline_model \\\n",
    "    .transform(val_df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()\n",
    "test_df = pipeline_model \\\n",
    "    .transform(test_df) \\\n",
    "    .select(F.col('_c0').alias('label'), 'features', 'id') \\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative subsampling and recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171867"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298142"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_train_df = train_df.filter(F.col('label') == 1.0)\n",
    "positive_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "873725"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_train_df = train_df.filter(F.col('label') == 0.0)\n",
    "negative_train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_params = {\n",
    "    'featuresCol': \"features\", \n",
    "    'labelCol': \"label\", \n",
    "    'predictionCol': \"prediction\",\n",
    "    'eval_metric': 'logloss',\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 1,\n",
    "    'silent': 0,\n",
    "    'nworkers': 1\n",
    "}\n",
    "\n",
    "baseline_params = {\n",
    "    'colsample_bytree': 0.9,\n",
    "    'eta': 0.15,\n",
    "    'gamma': 0.9,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 50.0,\n",
    "    'subsample': 0.9,\n",
    "    'num_round': 20\n",
    "}\n",
    "\n",
    "space = {**static_params, **baseline_params}\n",
    "\n",
    "# Results from several runs of hyperopt. The tuning procedure is the same as in hyperopt.ipynb notebook.\n",
    "\n",
    "space['num_round'] = 100\n",
    "space['eta'] = 0.3\n",
    "\n",
    "space['max_depth'] = 7\n",
    "space['min_child_weight'] = 50.0\n",
    "\n",
    "space['gamma'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_best_log_xgboost_model(train_df, val_df, negative_downsampling_rate):\n",
    "    time_start = time.time()\n",
    "\n",
    "    param1 = 'gamma'\n",
    "#     param2 = 'min_child_weight'\n",
    "    param1_choice  = [0.5, 0.8, 0.9, 0.95, 0.99]\n",
    "#     param2_choice = [10.0, 25.0, 50.0, 75.0, 100.0]\n",
    "    assert space[param1] in param1_choice\n",
    "#     assert space[param2] in param2_choice\n",
    "\n",
    "    space[param1] = hp.choice(param1, param1_choice)\n",
    "#     space[param2] = hp.choice(param2, param2_choice)\n",
    "    \n",
    "    def xgboost_objective(space):\n",
    "        estimator = XGBoostEstimator(**space)\n",
    "        success = False\n",
    "        attempts = 0\n",
    "        model = None\n",
    "        while not success and attempts < 2:\n",
    "            try:\n",
    "                model = estimator.fit(train_df)\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                attempts += 1\n",
    "                print(e)\n",
    "                print('Try again')\n",
    "\n",
    "        roc_auc = rocauc(\n",
    "            model, val_df, probabilities_col='probabilities', negative_downsampling_rate=negative_downsampling_rate)\n",
    "        calibr = calibration(\n",
    "            model, val_df, probabilities_col='probabilities', negative_downsampling_rate=negative_downsampling_rate)\n",
    "\n",
    "        print('LOSS: {}, ROC-AUC: {}, CALIBRATION: {}'.format(-roc_auc, roc_auc, calibr))\n",
    "        return {'loss': -roc_auc, 'rocauc': roc_auc, 'calibration': calibr, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    best_opt = fmin(\n",
    "        fn=xgboost_objective, space=space, algo=tpe.suggest, \n",
    "        max_evals=len(param1_choice), trials=trials)\n",
    "    space[param1] = param1_choice[best_opt[param1]]\n",
    "#     space[param2] = param2_choice[best_opt[param2]]\n",
    "    \n",
    "    estimator = XGBoostEstimator(**space)\n",
    "    print('Tuned params are', estimator._input_kwargs_processed())\n",
    "    model = estimator.fit(train_df)\n",
    "\n",
    "    time_finish = time.time()\n",
    "    print('Tuning time is ' + str(time_finish - time_start) + 's')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "MODEL's NEGATIVE DOWNSAMPLING RATE = 1.0\n",
      "LOSS: -0.7833087804512839, ROC-AUC: 0.7833087804512839, CALIBRATION: 0.43642035177855254\n",
      "LOSS: -0.7831396129778134, ROC-AUC: 0.7831396129778134, CALIBRATION: 0.43665626884059866\n",
      "LOSS: -0.7834431445233924, ROC-AUC: 0.7834431445233924, CALIBRATION: 0.4367349078612808\n",
      "LOSS: -0.7835186930781098, ROC-AUC: 0.7835186930781098, CALIBRATION: 0.43856981834386227\n",
      "LOSS: -0.7834431445233965, ROC-AUC: 0.7834431445233965, CALIBRATION: 0.4367349078612808\n",
      "100%|██████████| 5/5 [38:50<00:00, 466.16s/trial, best loss: -0.7835186930781098]\n",
      "Tuned params are {'eta': 0.3, 'subsample': 0.9, 'eval_metric': 'logloss', 'nworkers': 1, 'num_round': 100, 'nthread': 1, 'min_child_weight': 50.0, 'gamma': 0.9, 'colsample_bytree': 0.9, 'silent': 0, 'max_depth': 7, 'objective': 'binary:logistic', 'predictionCol': 'prediction', 'labelCol': 'label', 'featuresCol': 'features'}\n",
      "Tuning time is 3173.504271030426s\n",
      "Test metrics are {'Calibration Δ': 0.42160152821518915, 'Area Under ROC': 0.7808397201250101}\n"
     ]
    }
   ],
   "source": [
    "best_model, best_rocauc, best_downsampling_rate = None, None, None\n",
    "\n",
    "all_metrics = {}\n",
    "search_space = [1.0]\n",
    "for index, negative_downsampling_rate in enumerate(search_space, 1):\n",
    "    print('*' * 100)\n",
    "    print('MODEL\\'s NEGATIVE DOWNSAMPLING RATE = ' + str(negative_downsampling_rate))\n",
    "    rebalanced_train_df = negative_train_df \\\n",
    "        .sample(False, negative_downsampling_rate, seed=SEED) \\\n",
    "        .union(positive_train_df)\n",
    "    cur_model = find_the_best_log_xgboost_model(\n",
    "        rebalanced_train_df,\n",
    "        val_df,\n",
    "        negative_downsampling_rate)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[ROC_AUC_HANDLE] = rocauc(\n",
    "        cur_model, test_df, probabilities_col='probabilities', negative_downsampling_rate=negative_downsampling_rate)\n",
    "    metrics[CALIBRATION_HANDLE] = calibration(\n",
    "        cur_model, test_df, probabilities_col='probabilities', negative_downsampling_rate=negative_downsampling_rate)    \n",
    "    model_handle = index = str(index) + '.xgb_mte_' + str(negative_downsampling_rate)\n",
    "    all_metrics[model_handle] = metrics\n",
    "    print('Test metrics are', metrics)\n",
    "\n",
    "    cur_rocauc = metrics[ROC_AUC_HANDLE]\n",
    "    if best_rocauc is None or best_rocauc < cur_rocauc:\n",
    "        best_model = cur_model\n",
    "        best_rocauc = cur_rocauc\n",
    "        best_downsampling_rate = negative_downsampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space: [1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7808397201250101, 1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Search space:', search_space)\n",
    "best_rocauc, best_downsampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = '/workspace/models/criteo/dac'\n",
    "\n",
    "BEST_CTR_MODEL_NAME = 'ctr_model_' + str(best_downsampling_rate)\n",
    "BEST_CTR_MODEL_PATH = os.path.join(MODEL_DIR, BEST_CTR_MODEL_NAME)\n",
    "\n",
    "best_model._call_java(\"booster\").saveModel(BEST_CTR_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.xgb_mte_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Area Under ROC</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calibration Δ</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1.xgb_mte_1.0\n",
       "Area Under ROC            0.0\n",
       "Calibration Δ             0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_HANDLE = '1.xgb_mte_1.0'\n",
    "get_ate(all_metrics, BASELINE_HANDLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "917961"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DATA_PATH = '/workspace/data/mlbd-20-ctr-prediction-1'\n",
    "TEST_TEST_PATH = os.path.join(TEST_DATA_PATH, 'test.csv')\n",
    "\n",
    "comp_df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TEST_TEST_PATH) \\\n",
    "    .fillna(0, subset=num_columns)\n",
    "\n",
    "comp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229490\n",
      "229490\n",
      "229490\n",
      "229491\n"
     ]
    }
   ],
   "source": [
    "comp_df_parts = split_by_col(comp_df, 'id', [0.25, 0.25, 0.25, 0.25])\n",
    "for comp_df_part in comp_df_parts:\n",
    "    print(comp_df_part.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/data/mlbd-20-ctr-prediction-1/submission_ctr_model_1.0.csv\n"
     ]
    }
   ],
   "source": [
    "submission_path = os.path.join(TEST_DATA_PATH, 'submission_' + BEST_CTR_MODEL_NAME + '.csv')\n",
    "print(submission_path)\n",
    "\n",
    "with open(submission_path, 'w') as writer:\n",
    "    writer.write(\"id,proba\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(features=DenseVector([0.0, 19.0, 2.0, 4.0, 4576.0, 6.0, 6.0, 5.0, 15.0, 0.0, 2.0, 0.0, 4.0, 0.2542, 0.2578, 0.2544, 0.2517, 0.255, 0.33, 0.3165, 0.2544, 0.269, 0.3247, 0.3163, 0.2544, 0.3163, 0.2177, 0.3027, 0.2544, 0.3066, 0.3145, 0.2544, 0.2544, 0.2544, 0.2544, 0.2686, 0.2477, 0.2544, 0.2544]), id=566935904713, probabilities=DenseVector([0.5678, 0.4322]), prediction=0.0, proba=0.4322131872177124)]\n",
      "[Row(features=DenseVector([0.0, 20.0, 4.0, 6.0, 25653.0, 0.0, 0.0, 32.0, 6.0, 0.0, 0.0, 0.0, 6.0, 0.2534, 0.0815, 0.1303, 0.1582, 0.2474, 0.2469, 0.291, 0.2543, 0.269, 0.2159, 0.2671, 0.1303, 0.2671, 0.2177, 0.0682, 0.1303, 0.3066, 0.1005, 0.2544, 0.2544, 0.1303, 0.2544, 0.2418, 0.2021, 0.2544, 0.2544]), id=601295737752, probabilities=DenseVector([0.9743, 0.0257]), prediction=0.0, proba=0.02572101354598999)]\n",
      "[Row(features=DenseVector([0.0, 246.0, 2.0, 1.0, 0.0, 0.0, 0.0, 5.0, 28.0, 0.0, 0.0, 0.0, 1.0, 0.2635, 0.3072, 0.1611, 0.1613, 0.2543, 0.2469, 0.1104, 0.2543, 0.1278, 0.2159, 0.1104, 0.1611, 0.1879, 0.2177, 0.1507, 0.1611, 0.0973, 0.2009, 0.2544, 0.2544, 0.1611, 0.2544, 0.2686, 0.1613, 0.2544, 0.2544]), id=635655552866, probabilities=DenseVector([0.9446, 0.0554]), prediction=0.0, proba=0.05538378655910492)]\n",
      "[Row(features=DenseVector([3.0, -1.0, 0.0, 0.0, 8.0, 0.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.2542, 0.3072, 0.2544, 0.2544, 0.2543, 0.2196, 0.527, 0.262, 0.269, 0.2544, 0.4667, 0.2544, 0.4667, 0.273, 0.2544, 0.2544, 0.2223, 0.2544, 0.2544, 0.2544, 0.2544, 0.2544, 0.2177, 0.2544, 0.2544, 0.2544]), id=670015388346, probabilities=DenseVector([0.359, 0.641]), prediction=1.0, proba=0.6409794688224792)]\n"
     ]
    }
   ],
   "source": [
    "for comp_df_part in comp_df_parts:\n",
    "\n",
    "    comp_df_part = pipeline_model \\\n",
    "        .transform(comp_df_part) \\\n",
    "        .select('features', 'id') \\\n",
    "        .cache()\n",
    "\n",
    "    comp_df_part = df_with_proba_column(\n",
    "        best_model, comp_df_part, probabilities_col='probabilities',\n",
    "        negative_downsampling_rate=best_downsampling_rate)\n",
    "\n",
    "    print(comp_df_part.take(1))\n",
    "\n",
    "    comp_part_predictions = comp_df_part \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: (row.id, row.proba)) \\\n",
    "        .collect()\n",
    "\n",
    "    with open(submission_path, 'a') as writer:\n",
    "        for row in comp_part_predictions:\n",
    "            writer.write(\",\".join(map(str, row))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
