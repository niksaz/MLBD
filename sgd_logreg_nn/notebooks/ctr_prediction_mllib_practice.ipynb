{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#CTR-prediction\" data-toc-modified-id=\"CTR-prediction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CTR-prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Problem-Formulation\" data-toc-modified-id=\"Problem-Formulation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Problem Formulation</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset-construction:\" data-toc-modified-id=\"Dataset-construction:-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Dataset construction:</a></span></li><li><span><a href=\"#Format:\" data-toc-modified-id=\"Format:-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Format:</a></span></li></ul></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Metrics</a></span></li></ul></li><li><span><a href=\"#Dataset-preprocessing\" data-toc-modified-id=\"Dataset-preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#ML-Pipelines-(Transformers,-Estimators)\" data-toc-modified-id=\"ML-Pipelines-(Transformers,-Estimators)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-pipeline.html#pipeline-components\" target=\"_blank\">ML Pipelines (Transformers, Estimators)</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Prepare-stages-of-pipeline\" data-toc-modified-id=\"Prepare-stages-of-pipeline-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Prepare stages of pipeline</a></span></li><li><span><a href=\"#Fit-and-save-pipeline\" data-toc-modified-id=\"Fit-and-save-pipeline-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Fit and save pipeline</a></span></li><li><span><a href=\"#Load-fitted-pipeline\" data-toc-modified-id=\"Load-fitted-pipeline-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Load fitted pipeline</a></span></li><li><span><a href=\"#Transform-dataset-using-pipeline\" data-toc-modified-id=\"Transform-dataset-using-pipeline-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>Transform dataset using pipeline</a></span></li><li><span><a href=\"#Make-dataset-split\" data-toc-modified-id=\"Make-dataset-split-2.1.5\"><span class=\"toc-item-num\">2.1.5&nbsp;&nbsp;</span>Make dataset split</a></span></li></ul></li></ul></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html\" target=\"_blank\">Classification</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\" target=\"_blank\">Logistic Regression</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-and-Train-model\" data-toc-modified-id=\"Define-and-Train-model-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Define and Train model</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html\" target=\"_blank\">Evaluation</a></a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-classification-metrics\" data-toc-modified-id=\"Binary-classification-metrics-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span><a href=\"https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">Binary classification metrics</a></a></span></li><li><span><a href=\"#Make-submission\" data-toc-modified-id=\"Make-submission-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Make submission</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTR-prediction\n",
    "\n",
    "## Problem Formulation\n",
    "\n",
    "$\\newcommand{\\vecw}{{\\bf w}}$\n",
    "$\\newcommand{\\vecx}{{\\bf x}}$\n",
    "\n",
    "* Dataset: $X^N = \\{ z_i \\}^N_{i=1}$, где $z_i = (\\vecx_i, y_i) \\sim P(z), y_i \\in \\{0,1\\}$\n",
    "* Prediction: $$ \\hat{y}_i = f_{\\vecw}(\\vecx_i) =  \\mathbb{P} \\left\\{ y = 1 \\mid \\vecx_i \\right\\} $$\n",
    "* Loss function (Binary Cross-Entropy): $$ \\min\\limits_{\\vecw} \\quad \\frac{\\lambda}{2}\\| \\vecw \\|^2_2 - \\frac{1}{N} \\sum\\limits_{i=1}^{N} y_i \\log \\hat{y}_i + (1-y_i) \\log(1-\\hat{y}_i) $$\n",
    "\n",
    "## Dataset\n",
    "$ $\n",
    "<details>\n",
    "  <summary>Click here to see the details</summary>\n",
    "\n",
    "For more details see `/data/criteo/readme.txt`\n",
    "\n",
    "### Dataset construction:\n",
    "\n",
    "\n",
    ">There are 13 features taking **integer** values and 26\n",
    "**categorical** features. The values of the categorical features have been hashed\n",
    "onto 32 bits for anonymization purposes. \n",
    "Some features may have missing values.\n",
    "\n",
    "> The rows are chronologically ordered by `id` column.\n",
    "\n",
    "> The test set corresponds to events on the day following the training period. \n",
    "The first column (`label`) has been removed.\n",
    "\n",
    "\n",
    "### Format:\n",
    "\n",
    "> The columns are comma separeted with the following schema:\n",
    "`<label>,<integer feature 1>, ... <integer feature 13>,<categorical feature 1>, ... <categorical feature 26>,<id>`\n",
    "\n",
    "> When a value is missing, the field is \"\". There is no `label` field in the test set.\n",
    "\n",
    "</details>\n",
    "    \n",
    "## Metrics\n",
    "\n",
    "The evaluation metrics for this task are\n",
    "* ROC AUC\n",
    "* LogLoss\n",
    "* [Normalized Entropy](https://quinonero.net/Publications/predicting-clicks-facebook.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"spark_sql_examples\") \\\n",
    "    .config(\"spark.executor.memory\", \"6g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_DATA_PATH = '/workspace/data/criteo/dac'\n",
    "\n",
    "DEV_TRAIN_PATH = os.path.join(DEV_DATA_PATH, 'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin our introduction to Spark [MLlib](https://spark.apache.org/docs/latest/ml-guide.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset preprocessing\n",
    "\n",
    "Before we can train any prediction model on our dataset we need to conver each row into real-valued features vector ($\\vecx \\in \\mathbb{R}^n$).\n",
    "\n",
    "Spark MLlib provides easy to use tools for preprocessing raw features and turning them into suitable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + DEV_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(False, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      " |-- _c29: string (nullable = true)\n",
      " |-- _c30: string (nullable = true)\n",
      " |-- _c31: string (nullable = true)\n",
      " |-- _c32: string (nullable = true)\n",
      " |-- _c33: string (nullable = true)\n",
      " |-- _c34: string (nullable = true)\n",
      " |-- _c35: string (nullable = true)\n",
      " |-- _c36: string (nullable = true)\n",
      " |-- _c37: string (nullable = true)\n",
      " |-- _c38: string (nullable = true)\n",
      " |-- _c39: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping only first two categorical features for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = ['_c{}'.format(i) for i in range(1, 14)]\n",
    "cat_columns = ['_c{}'.format(i) for i in range(14, 40)][:2]\n",
    "len(num_columns), len(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0, subset=num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ML Pipelines (Transformers, Estimators)](https://spark.apache.org/docs/latest/ml-pipeline.html#pipeline-components)\n",
    "\n",
    "\n",
    "MLlib standardizes APIs for machine learning algorithms to make it easier to combine multiple algorithms into a single pipeline, or workflow.\n",
    "\n",
    "* `Transformer`: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms a DataFrame with features into a DataFrame with predictions.\n",
    "\n",
    "\n",
    "* `Estimator`: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n",
    "\n",
    "\n",
    "* `Pipeline`: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n",
    "\n",
    "---\n",
    "Basically speaking `transformer` is an instance of class that implements `transform` method, and both `estimator` and `pipeline` implements `transform` and `fit` methods.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare stages of pipeline\n",
    "\n",
    "We might benefit from using `StringIndexer, OneHotEncoderEstimator, VectorAssembler` (see [doc](https://spark.apache.org/docs/latest/ml-features) for details) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoderEstimator, VectorAssembler\n",
    "\n",
    "\n",
    "# Configure an ML pipeline\n",
    "cat_index_columns = [col_name + \"_index\" for col_name in cat_columns]\n",
    "cat_vec_columns = [col_name + \"_vec\" for col_name in cat_columns]\n",
    "cat_indexer_0 = StringIndexer(inputCol=cat_columns[0], outputCol=cat_index_columns[0], handleInvalid='keep')\n",
    "cat_indexer_1 = StringIndexer(inputCol=cat_columns[1], outputCol=cat_index_columns[1], handleInvalid='keep')\n",
    "ohe_estimator = OneHotEncoderEstimator(\n",
    "    inputCols=[cat_index_columns[0], cat_index_columns[1]],\n",
    "    outputCols=[cat_vec_columns[0], cat_vec_columns[1]])\n",
    "\n",
    "columns_to_assemble = []\n",
    "columns_to_assemble.extend(num_columns)\n",
    "columns_to_assemble.extend(cat_vec_columns)\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=columns_to_assemble, outputCol=\"features\")\n",
    "\n",
    "df_pipeline = Pipeline(stages=[cat_indexer_0, cat_indexer_1, ohe_estimator, vector_assembler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and save pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '/workspace/models/criteo/dac'\n",
    "\n",
    "DF_PIPELINE_PATH = os.path.join(MODEL_PATH, 'df_pipeline')\n",
    "\n",
    "df_pipeline.fit(df).write().overwrite().save(DF_PIPELINE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fitted pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "\n",
    "pipeline_model = PipelineModel.load(DF_PIPELINE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dataset using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=29, features=SparseVector(1957, {0: 3.0, 2: 4.0, 3: 13.0, 4: 224.0, 5: 28.0, 6: 3.0, 7: 35.0, 8: 27.0, 9: 1.0, 10: 1.0, 12: 13.0, 13: 1.0, 1432: 1.0}), label=1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df = pipeline_model \\\n",
    "    .transform(df) \\\n",
    "    .selectExpr('id as id', 'features as features', '_c0 as label')\n",
    "transformed_df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset split\n",
    "\n",
    "Spark provides [randomSplit](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit) method.\n",
    "\n",
    "It is not the best choice in our task since we have chronological order in data.\n",
    "\n",
    "We need to implement our own split function which will split the data in parts with respect to chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def split_by_col(df, split_col, parts_fractions):\n",
    "    \"\"\"\n",
    "    df - DataFrame\n",
    "    split_col - total order column\n",
    "    parts_fractions - fractions of resulting parts\n",
    "    \"\"\"\n",
    "    N = df.count()\n",
    "    ids_sample = df \\\n",
    "        .select(split_col) \\\n",
    "        .sample(False, 0.01) \\\n",
    "        .collect()\n",
    "    N_sample = len(ids_sample)\n",
    "    print(\"Ids size is:\", N)\n",
    "    print(\"Ids sample size is:\", N_sample)\n",
    "    \n",
    "    parts = []\n",
    "    ids_sample = sorted(ids_sample)\n",
    "    cumulative_part = 0.0\n",
    "    before_id = None\n",
    "    for next_part in parts_fractions:\n",
    "        cumulative_part += next_part\n",
    "        next_id_index = math.ceil(N_sample * cumulative_part)\n",
    "        if next_id_index >= N_sample:\n",
    "            next_id = None\n",
    "        else:\n",
    "            next_id = ids_sample[next_id_index][0]\n",
    "        \n",
    "        part = df\n",
    "        if before_id is None and next_part is None and next_part * N_samples < 1:\n",
    "            # Empty dataframe\n",
    "            part = part.filter(F.col(split_col).isNull())\n",
    "        else:\n",
    "            if before_id is not None:\n",
    "                part = part.filter(F.col(split_col) >= before_id)\n",
    "            if next_id is not None:\n",
    "                part = part.filter(F.col(split_col) < next_id)\n",
    "        parts.append(part)\n",
    "    \n",
    "        before_id = next_id     \n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ids size is: 1834709\n",
      "Ids sample size is: 18336\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = split_by_col(transformed_df, 'id', [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = transformed_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7956068237524316, 0.10398542766182539, 0.10040774858574303)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count() / N, val_df.count() / N, test_df.count() / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "\n",
    "def _get_score_and_labels(model, df):\n",
    "    return model \\\n",
    "        .transform(df) \\\n",
    "        .selectExpr('probability as probability', 'label as label') \\\n",
    "        .rdd \\\n",
    "        .map(lambda row: (float(row.probability[1]), float(row.label)))\n",
    "\n",
    "\n",
    "def _logloss_from_score_and_labels(score_and_labels):\n",
    "    return score_and_labels \\\n",
    "        .map(lambda score_label: -(\n",
    "            score_label[1]*np.log(score_label[0])\n",
    "            + (1.0-score_label[1])*np.log(1.0-score_label[0]))) \\\n",
    "        .mean()\n",
    "    \n",
    "\n",
    "def rocauc(model, df):\n",
    "    score_and_labels = _get_score_and_labels(model, df)\n",
    "    metrics = BinaryClassificationMetrics(score_and_labels)\n",
    "    return metrics.areaUnderROC\n",
    "\n",
    "\n",
    "def logloss(model, df):\n",
    "    score_and_labels = _get_score_and_labels(model, df)\n",
    "    logloss = _logloss_from_score_and_labels(score_and_labels)\n",
    "    return logloss\n",
    "\n",
    "\n",
    "def ne(model, df):\n",
    "    score_and_labels = _get_score_and_labels(model, df)\n",
    "    nominator = _logloss_from_score_and_labels(score_and_labels)\n",
    "    mean_ctr = score_and_labels.map(lambda row: row[1]).mean()\n",
    "    denominator = -(mean_ctr*np.log(mean_ctr) + (1-mean_ctr)*np.log(1-mean_ctr))\n",
    "    return nominator/denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [Classification](https://spark.apache.org/docs/latest/ml-classification-regression.html)\n",
    "\n",
    "## [Logistic Regression](https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression)\n",
    "\n",
    "### Define and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved ROCAUC from None to 0.7024240908087696 with params:\n",
      "regParam=0.0 elasticNetParam=0.0 standardization=True\n",
      "Improved ROCAUC from 0.7024240908087696 to 0.7024240908087722 with params:\n",
      "regParam=0.0 elasticNetParam=0.0 standardization=False\n",
      "Improved ROCAUC from 0.7024240908087722 to 0.7024240908087724 with params:\n",
      "regParam=0.0 elasticNetParam=0.01 standardization=True\n",
      "Improved ROCAUC from 0.7024240908087724 to 0.702590587968243 with params:\n",
      "regParam=0.01 elasticNetParam=0.1 standardization=True\n",
      "Improved ROCAUC from 0.702590587968243 to 0.7028322080612285 with params:\n",
      "regParam=0.001 elasticNetParam=0.1 standardization=True\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "best_model = None\n",
    "best_rocauc = None\n",
    "for regParam in [0.0, 1e-1, 1e-2, 1e-3]:\n",
    "    for elasticNetParam in [0.0, 1e-1, 1e-2, 1e-3]: \n",
    "        for standardization in [True, False]:\n",
    "            lr = LogisticRegression(\n",
    "                regParam=regParam, elasticNetParam=elasticNetParam, standardization=standardization)\n",
    "            lr_model = lr.fit(train_df)\n",
    "            lr_rocauc = rocauc(lr_model, val_df)\n",
    "            if best_rocauc is None or best_rocauc < lr_rocauc:\n",
    "                print(\"Improved ROCAUC from {} to {} with params:\".format(best_rocauc, lr_rocauc))\n",
    "                print(\"regParam={} elasticNetParam={} standardization={}\".format(\n",
    "                    regParam, elasticNetParam, standardization))\n",
    "                best_model = lr_model\n",
    "                best_rocauc = lr_rocauc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=446677060223, features=SparseVector(1957, {1: 2.0, 2: 16.0, 3: 11.0, 4: 1.0, 5: 128.0, 6: 1.0, 7: 47.0, 8: 180.0, 10: 1.0, 12: 4.0, 13: 1.0, 1407: 1.0}), label=0, rawPrediction=DenseVector([1.7593, -1.7593]), probability=DenseVector([0.8531, 0.1469]), prediction=0.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.transform(val_df).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# [Evaluation](https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html)\n",
    "\n",
    "## [Binary classification metrics](https://spark.apache.org/docs/2.1.0/mllib-evaluation-metrics.html#binary-classification)\n",
    "\n",
    "* ROC AUC\n",
    "* LogLoss\n",
    "* Normalized Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocauc 0.7028322080612296\n",
      "logloss 0.5266542614101842\n",
      "ne 0.917777896552764\n",
      "rocauc 0.7002145947660112\n",
      "logloss 0.5310748677287841\n",
      "ne 0.9203894127198535\n"
     ]
    }
   ],
   "source": [
    "for cur_df in [val_df, test_df]:\n",
    "    print(\"rocauc\", rocauc(best_model, cur_df))\n",
    "    print(\"logloss\", logloss(best_model, cur_df))\n",
    "    print(\"ne\", ne(best_model, cur_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission\n",
    "\n",
    "Join the [competition](https://www.kaggle.com/c/mlbd-20-ctr-prediction-1) and make a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA_PATH = '/workspace/data/mlbd-20-ctr-prediction-1'\n",
    "\n",
    "TEST_TEST_PATH = os.path.join(TEST_DATA_PATH, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = sqlContext.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load('file:///' + TEST_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      " |-- _c29: string (nullable = true)\n",
      " |-- _c30: string (nullable = true)\n",
      " |-- _c31: string (nullable = true)\n",
      " |-- _c32: string (nullable = true)\n",
      " |-- _c33: string (nullable = true)\n",
      " |-- _c34: string (nullable = true)\n",
      " |-- _c35: string (nullable = true)\n",
      " |-- _c36: string (nullable = true)\n",
      " |-- _c37: string (nullable = true)\n",
      " |-- _c38: string (nullable = true)\n",
      " |-- _c39: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = comp_df.fillna(0, subset=num_columns)\n",
    "transformed_comp_df = pipeline_model.transform(comp_df)\n",
    "comp_df_prediction = best_model.transform(transformed_comp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c1=0, _c2=19, _c3=2, _c4=4, _c5=4576, _c6=6, _c7=6, _c8=5, _c9=15, _c10=0, _c11=2, _c12=0, _c13=4, _c14='05db9164', _c15='b961056b', _c16='bc015839', _c17='4120ff84', _c18='4cf72387', _c19='6f6d9be8', _c20='2682a57d', _c21='5b392875', _c22='a73ee510', _c23='3f25d8e4', _c24='f7433a43', _c25='b838627b', _c26='4fce4e51', _c27='b28479f6', _c28='70a601bc', _c29='0c0bfddd', _c30='e5ba7672', _c31='43de85d3', _c32=None, _c33=None, _c34='b64021bd', _c35=None, _c36='32c7478e', _c37='f1a27f66', _c38=None, _c39=None, id=566935904713, _c14_index=0.0, _c15_index=31.0, _c14_vec=SparseVector(1392, {0: 1.0}), _c15_vec=SparseVector(552, {31: 1.0}), features=SparseVector(1957, {1: 19.0, 2: 2.0, 3: 4.0, 4: 4576.0, 5: 6.0, 6: 6.0, 7: 5.0, 8: 15.0, 10: 2.0, 12: 4.0, 13: 1.0, 1436: 1.0}), rawPrediction=DenseVector([1.1504, -1.1504]), probability=DenseVector([0.7596, 0.2404]), prediction=0.0)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df_prediction.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=566935904713, probability=DenseVector([0.7596, 0.2404]))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df_prediction = comp_df_prediction.select(F.col('id'), F.col('probability'))\n",
    "comp_df_prediction.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_predictions = comp_df_prediction \\\n",
    "    .rdd \\\n",
    "    .map(lambda row: (row.id, row.probability[1])) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_path = os.path.join(TEST_DATA_PATH, 'submission.csv')\n",
    "with open(submission_path, 'w') as writer:\n",
    "    writer.write(\"id,proba\\n\")\n",
    "    for row in comp_predictions:\n",
    "        writer.write(\",\".join(map(str, row))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
